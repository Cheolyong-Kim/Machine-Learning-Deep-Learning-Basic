{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84de0ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f082c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('day7_data2_X.npy')\n",
    "y = np.load('day7_data2_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b673181",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = LogisticRegression(random_state= 1)\n",
    "c2 = DecisionTreeClassifier(random_state= 1)\n",
    "c3 = GaussianNB()\n",
    "\n",
    "ec = VotingClassifier(estimators= [('lr', c1), ('rf', c2), ('gnb', c3)], voting= 'hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c7fd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8009268075922046"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(ec, X, y, cv= 5).mean()\n",
    "# 항상 앙상블 모델이 가장 좋은 성능을 내는 것이 아님\n",
    "# 해당 예제에서는 세번째 모델이 성능이 아주 낮아서 앙상블의 스코어 값이 나머지 두 모델의 스코어 값보다 낮게 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7333f0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8290420872214816"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(c1, X, y, cv= 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884794ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7829175395162826"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(c2, X, y, cv= 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e27a028b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4600139655938551"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(c3, X, y, cv= 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53bb3a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8222687742017394"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec1 = VotingClassifier(estimators= [('lr', c1), ('dt', c2)], voting= 'hard')\n",
    "cross_val_score(ec1, X, y, cv= 5).mean()\n",
    "# 가장 성능이 안좋은 세번째 모델을 제거해서 스코어 값을 좋게 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa9edc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_params = [0.1, 5.0, 7.0, 10.0, 15.0, 20.0, 100.0]\n",
    "params = {\n",
    "    'lr__solver': ['liblinear'],\n",
    "    'lr__penalty': ['l2'],\n",
    "    'lr__C': c_params,\n",
    "    'dt__criterion': ['gini', 'entropy'],\n",
    "    'dt__max_depth': [10, 8, 7, 6, 5, 4, 3, 2],\n",
    "    'dt__min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b74711ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8425569732749316"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "g = GridSearchCV(estimator= ec1, param_grid= params, cv= 5)\n",
    "g.fit(X, y)\n",
    "g.best_score_\n",
    "\n",
    "# 투표 분류기에 들어갈 모델들의 하이퍼 매개변수를 조정하여 앙상블 스코어를 더 좋게 만들 수 있다\n",
    "# 교차 검증을 통해 가장 좋은 스코어를 내는 파라미터들을 찾는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3da621a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dt__criterion': 'gini',\n",
       " 'dt__max_depth': 10,\n",
       " 'dt__min_samples_leaf': 5,\n",
       " 'lr__C': 5.0,\n",
       " 'lr__penalty': 'l2',\n",
       " 'lr__solver': 'liblinear'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2297b836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8425569732749316"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 찾은 파라미터들을 투표 분류기에 넣을 모델에 직접 설정하면 좋은 스코어를 낼 수 있다.\n",
    "c1 = LogisticRegression(solver= 'liblinear', penalty= 'l2', C= 5.0, random_state= 1)\n",
    "c2 = DecisionTreeClassifier(criterion= 'gini', max_depth= 10, min_samples_leaf= 5, random_state= 1)\n",
    "\n",
    "ec3 = VotingClassifier(estimators= [('A', c1), ('B', c2)], voting= 'hard')\n",
    "\n",
    "cross_val_score(ec3, X, y, cv= 5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c46832",
   "metadata": {},
   "source": [
    "### 정리 조합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b40d32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8425569732749316"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "X = np.load('day7_data2_X.npy')\n",
    "y = np.load('day7_data2_y.npy')\n",
    "\n",
    "c1 = LogisticRegression(solver= 'liblinear', penalty= 'l2', C= 5.0, random_state= 1)\n",
    "c2 = DecisionTreeClassifier(criterion= 'gini', max_depth= 10, min_samples_leaf= 5, random_state= 1)\n",
    "\n",
    "ec = VotingClassifier(estimators= [('c1', c1), ('c2', c2)], voting= 'hard')\n",
    "\n",
    "cross_val_score(ec, X, y, cv= 5).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
